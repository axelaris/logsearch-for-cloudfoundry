---
meta: (( merge ))
networks: (( merge ))
name: (( merge ))

properties:
  <<: (( merge ))
  collector:
    deployment_name: CF
    use_gelf: true
    gelf:
      address: 127.0.0.1
  nats:
    password: (( merge ))
    user: (( merge ))
    port: (( merge || 4222 ))
    machines: (( merge ))
  curator:
    <<: (( merge ))
    elasticsearch_host: (( jobs.elasticsearch_master.networks.default.static_ips.[0] ))
    purge_logs: 
      retention_period: 7 
  logstash_parser:
    <<: (( merge ))
    debug: false
    elasticsearch_index: "logs-%{[@metadata][index]}-%{+YYYY.MM.dd}"
    elasticsearch_index_type: "%{[@metadata][type]}"
  logstash_ingestor:
    <<: (( merge ))
    debug: false
    syslog:
      port: 514
  push-kibana:
    app_name: logs
    oauth2_client_id: logsearch-for-cloudfoundry
    oauth2_client_secret: (( merge )) 
  redis:
    host: (( jobs.queue.networks.default.static_ips.[0] ))
  elasticsearch:
    <<: (( merge ))
    admin_ip: (( jobs.elasticsearch_master.networks.default.static_ips.[0] )) 
    master_hosts: 
    - (( jobs.elasticsearch_master.networks.default.static_ips.[0] ))
    log_level: INFO
    discovery:
      minimum_master_nodes: 1
    host: (( jobs.elasticsearch_master.networks.default.static_ips.[0] ))  #NB This should contain all the elasticsearch_master IPs
    cluster_name: (( name ))
  elasticsearch_config:
    elasticsearch:
      host: (( jobs.elasticsearch_master.networks.default.static_ips.[0] ))
  cloudfoundry:
    skip_ssl_validation: true
    system_domain: (( merge )) 
    api_access_security_group: (( merge )) 
    firehose_port: (( merge ))
    firehose_user: (( merge ))
    firehose_password: (( merge ))
    admin_username: (( merge ))
    admin_password: "(( merge ))"
    admin_client_secret: "(( merge ))" 

jobs:
- name: elasticsearch_master
  templates:
  - { release: logsearch, name: api }
  - { release: logsearch, name: elasticsearch }
  - { release: logsearch, name: elasticsearch_config }
  - { release: logsearch, name: curator }
  instances: 1
  update:
    serial: true
  resource_pool: medium
  networks:
  - name: default
    static_ips: (( static_ips(0) ))
  persistent_disk_pool: elasticsearch_master
  properties:
    elasticsearch:
      <<: (( merge ))
      node:
        allow_master: true
        allow_data: false

- name: elasticsearch_data
  templates:
  - { release: logsearch, name: elasticsearch }
  instances: 2
  resource_pool: high_memory
  networks:
  - name: default
  persistent_disk_pool: elasticsearch_data
  properties:
    elasticsearch:
      <<: (( merge ))
      node:
        allow_master: false
        allow_data: true

- name: queue
  templates:
  - { release: logsearch, name: queue }
  instances: 1
  update:
    serial: true
  resource_pool: high_memory
  persistent_disk_pool: queue
  networks:
  - name: default
    static_ips: (( static_ips(1) ))

- name: parser
  templates:
  - { release: logsearch, name: parser }
  instances: 1
  resource_pool: high_cpu
  networks:
  - name: default

- name: ingestor_syslog
  templates:
  - { release: logsearch, name: ingestor_syslog }
  - { release: logsearch, name: ingestor_relp }
  instances: 1
  resource_pool: medium
  networks:
  - name: default
    static_ips: (( static_ips(2) ))

- name: ingestor_firehose
  templates:
  - { release: logsearch-for-cloudfoundry, name: ingestor_cloudfoundry-firehose }
#  - { release: logsearch-for-cloudfoundry, name: collector }
  instances: 1
  resource_pool: medium
  networks:
  - name: default

- name: push-kibana
  templates:
  - { release: logsearch-for-cloudfoundry, name: push-kibana }
  lifecycle: errand
  instances: 1
  resource_pool: tiny
  networks:
  - name: default

